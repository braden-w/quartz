# EA - A Survey of the Potential Long-term Impacts of AI by Sam Clarke

![rw-book-cover](https://images.weserv.nl/?url=https%3A%2F%2Fspeechkit-prod.s3.eu-west-1.amazonaws.com%2Fdistribution_images%252Fdistribution%252F%252FNonlinearnormal.png&w=100&h=100)

## Metadata
- Author: [[The Nonlinear Library]]
- Full Title: EA - A Survey of the Potential Long-term Impacts of AI by Sam Clarke
- Category: #podcasts
- URL: https://share.snipd.com/episode/d9c12765-4774-437d-96b2-75a95ac08dfa

## Highlights
- Attacking AI Related Intrastructure
  Summary:
  The use of a i capabilities may make it less clear where attacks originate from, making it easier for aggressors to obfiscate an attack. The very digital technologies that make militaries effective on the battlefield also introduce critical new vulnerabilities. Conflict is in general a de stabilizing factor which reduces our ability to mitigate other potential global catastrophes and steer towards a flourishing future for humanity.
  Transcript:
  Speaker 1
  A i may also offer more extreme first strike advantages or novel destructive capabilities that could disrupt deterrence, such as siber capabilities. Being used to knock out opponents. Nuclear command and control, defot 20 20, garfinkle and defo 20 19. The use of a i capabilities may make it less clear where attacks originate from, making it easier for aggressors to obfiscate an attack, and therefore reducing the costs of initiating one. By making it more difficult to explain their military decisions. A i may give states a cart blanche to act more aggressively. Diket a 20 19, by creating a wider and more vulnerable attack surface. A i related intrastructure may make war more tempting by lowering the cost of offensive action. For example, it might be sufficient to attack just data centers to do substantial harm. Or by creating a use them or lose them dynamic around powerful, yet vulnerable military a i systems. In this way, a i exasperate the capability vulnerability paradox. Schneider 20 16, where the very digital technologies that make militaries effective on the battlefield also introduce critical new vulnerabilities. A i development may itself become a new flash point for conflicts, causing more conflict to occur, especially conflicts over a i relevant resources such as data centers semi conductor manufacturing facilities and raw materials, alongside the possibility that a e will make globally catastrophic outcomes from conflict more likely. Conflict is in general a de stabilizing factor which reduces our ability to mitigate other potential global catastrophes and steer towards a flourishing future for humanity. ([Time 0:17:16](https://share.snipd.com/snip/15f47f86-7e78-46ba-ae9f-e028b2425875))
- Strategic Threats by Advanced AI Systems
  Summary:
  conflict is in general a de stabilizing factor which reduces our ability to mitigate other potential global catastrophes and steer towards a flourishing future for humanity. Clifton, 20 19, whilst strategic threats have been a concern long before recent a i progress, the risk may increase significantly with the advent of advance ai systems. In particular, if it's possible to create digital people, or other digital entities with moral patient hood, then advanced a i systems could be incentivied to threaten the creation of astronomical numbers of suffering digital people as a way of furthering their own goals - even if those goals are immoral. Furthermore advanced aight i might enable unprecedented levels of credibility in making threats by being
  Transcript:
  Speaker 1
  Conflict is in general a de stabilizing factor which reduces our ability to mitigate other potential global catastrophes and steer towards a flourishing future for humanity. For instance, conflict tends to erote international trust and co operation and increases risks posed by a range of weapon technologies. Or 20 20, risks from conflict between a i systems. Finally, as a i systems become more capable and integral to society, we may also need to consider potential conflicts that could arise n a i systems, and especially the results of strategic threats by powerful a i systems, or a i assisted humans against altruistic values. Clifton, 20 19, whilst strategic threats have been a concern long before recent a i progress, and were especially dangerous in the cold war, the risk may increase significantly with the advent of advance ai systems. In particular, the potential ability of advanced a i systems to cause astronomical suffering makes the potential downsid of strategic threats much larger than it has been previously. That is, if it's possible to create digital people, or other digital entities with moral patient hood, then advanced a i systems, even a moral one, could be incentivied to threaten the creation of astronomical numbers of suffering digital people as a way of furthering their own goals, even if those goals are immoral. Furthermore advanced aight i might enable unprecedented levels of credibility in making threats, for example, by being very transparent, thus making threats more attractive. Clifton 20 19, along with strategic threats, conflict could ensue ([Time 0:18:36](https://share.snipd.com/snip/86f968dc-1d6f-43cb-8aa2-9b9488fd1ba4))
- The Impact of Persuasion Tools on Society's Epistemic Processes
  Summary:
  We are seeing how a eye can be used to scale up the production of convincing, yet false or misleading information on line. Even without deliberate misuse, widespread use of powerful persuasion tools could have negative impacts. If such tools were used by many different groups to advance many different ideas, we could see the world splintering into isolated, epistemic communities with little room for dialogue or transfer between communities. A similar scenario could emerge via the increasing personalization of people's on line experiences. In other words, we may see a trend towards filter bubbles, echo chambers driven by content selection algorithms, that some argue is already happening.
  Transcript:
  Speaker 1
  At the same time, we are seeing how a eye can be used to scale up the production of convincing, yet false or misleading information on line, for example, via image, audio and text synthesis models like big gon broet al 20 19 and gpt three brown eda 20 20, as a a capabilities advance, they may be used to develop sophisticated persuasion tools, such as those that tailor their communication to specific users to persuade them of certain claims. Coco tilo 20 20, a while these tools could be used for social good, such as new york times chatbot that helps use s to persuade people to get vaccinated against covat 19, gagner and tamrius 20 21, there are also many ways they could be misused by self interested groups to gain influence and or to promote harmful ideologies. Even without deliberate misuse, widespread use of powerful persuasion tools could have negative impacts. If such tools were used by many different groups to advance many different ideas, we could see the world splintering into isolated, epistemic communities with little room for dialogue or transfer between communities. A similar scenario could emerge via the increasing personalization of people's on line experiences. In other words, we may see a continuation of the trend towards filter bubbles, echo chambers driven by content selection algorithms, that some argue is already happening. Barbara et al 20 15, flaxman etal 20 16. Minetal 20 14, in addition, the increased awareness of these trends in information production and distribution could make it harder for anyone to evaluate the trustworthiness of any information source, reducing overall trust in information. ([Time 0:30:42](https://share.snipd.com/snip/1ad56c28-130c-4940-9185-206ff76d7c8d))
- The Values That Steer Humanity's Future
  Summary:
  advanced a is likely to have a large impact on the values that steer humanity's future. What governments levers are available for reducing the risk of persuasion tools and on line personalization under mining epistemic processes? Are there data sets we could collect to help with measuring relevant properties of a i systems, like the extent to which they help rather than persuade their users?
  Transcript:
  Speaker 1
  There are also important estions relating to governments. What governments levers are available for reducing the risk of persuasion tools and on line personalization under mining epistemic processes? Are there data sets we could collect to help with measuring relevant properties of a i systems, like the extent to which they help rather than persuade their users, six the values that steer humanity's future. One way or another, advanced a is likely to have a large impact on the values that steer humanity's future. So far in human history, it seems like the future has largely been determined by competitive pressures, rather than by deliberate attempts by humans to shape the future according to their values. That is, if some technical in tutional or cultural innovation offers a competitive advantage, then its proliferation is highly likely. Some examples include firearms. In the tokagawa period of japanese history, up until 18 53, firearms technology was largely eliminated in japan, and a samurai dominated social order persisted for over 200 years. But then, in order to repel the threat of western colonization, japan was forced to re adopt firearms, along with other western customs and institutions, despite this running contrary to the values of the japanese elite. Pre one thousand 853 defot 20 15. Agriculture. Hunter gatherer soci s which did not adapt to agriculture were gradually killed off by farming societies who could grow larger due to increased food production. Industrialization. States which did not industrialize after the first industrial revolution rapidly fell behind in economic production and national competitiveness. ([Time 0:33:06](https://share.snipd.com/snip/d37cc52c-46f4-4716-92e2-6354ba0cae46))
