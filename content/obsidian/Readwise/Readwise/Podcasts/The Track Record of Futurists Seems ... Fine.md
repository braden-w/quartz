# The Track Record of Futurists Seems ... Fine

![rw-book-cover](https://images.weserv.nl/?url=https%3A%2F%2Fstorage.buzzsprout.com%2Fvariants%2F90shsndynh0ulb3epxefqsghh9ir%2F60854458c4d1acdf4e1c2f79c4137142d85d78e379bdafbd69bd34c85f5819ad.jpg&w=100&h=100)

## Metadata
- Author: [[Cold Takes Audio]]
- Full Title: The Track Record of Futurists Seems ... Fine
- Category: #podcasts
- URL: https://share.snipd.com/episode/7b6d5d5c-43aa-4aec-badf-8802cf71c6b7

## Highlights
- Are We Really Good at Predicting Future Events?
  Summary:
  This is holden karnowski doing an amateur read through of my blog post. The track record of futurists seems fine. I've argued that the development of advanced dei could make this the most important century for humanity. But are people generally bad at predicting far future events, including thoughtful people who are trying reason hard to be right? If we look back at prominent futurist predictions, what's the actual track record? How bad is the situation? open philanthropys luk muelhauser has put in a fair amount of effort into researching it.
  Transcript:
  Speaker 1
  This is holden karnowski doing an amateur read through of my blog post. The track record of futurists seems fine. I've argued that the development of advanced dei could make this the most important century for humanity. A common reaction to this idea is one laid out by tyler cowan in a piece that i link to, where he says, how good we're, past thinkers, at predicting the future. Don't just select on those who are famous because they got some big things right now. This is a common reason people give for being sceptical about the most important century hypothesis, and often for scepticism about pretty much any attempt at futurism, trying to predict key event in the world a long time from now, or what i call steering, trying to help the world navigate key future events. The idea of the scepticism is something like, even if we can't identify a particular weakness in arguments about key future events, perhaps we should be sceptical of our own ability to say anything meaningful at all the long run future. Hence, perhaps we should forget about theories of the future and focus on reducing suffering to day. Generally, increasing humanity's capabilities and technologies, et cetera. But are people generally bad at predicting far future events, including thoughtful people who are trying reason hard to be right? If we look back at prominent futurist predictions, what's the actual track record? How bad is the situation? I've looked pretty far and wide for systematic answers to this question, and open philanthropys luk muelhauser, has put in a fair amount of effort into researching it. I link to a couple of his reports. So far, we haven't turned up a whole lot. The main observation is that it's hard to judge the track record of futurists. Luke discusses the difficulties in a piece that i link to, and an appendix to this piece that ill read goes through a bunch of bunch of things. Now, recently i worked with ar research to take another crack at this. I tryd to keep things simpler with past attempts. ([Time 0:00:00](https://share.snipd.com/snip/efa2b38b-87e8-483c-89fd-579573d30239))
- The Most Important Century Hypothesis
  Summary:
  I've argued that the development of advanced dei could make this the most important century for humanity. A common reaction to this idea is one laid out by tyler cowan in a piece that i link to, where he says, how good we're, past thinkers, at predicting the future. This is a common reason people give for being sceptical about the most important Century hypothesis.
  Transcript:
  Speaker 1
  This is holden karnowski doing an amateur read through of my blog post. The track record of futurists seems fine. I've argued that the development of advanced dei could make this the most important century for humanity. A common reaction to this idea is one laid out by tyler cowan in a piece that i link to, where he says, how good we're, past thinkers, at predicting the future. Don't just select on those who are famous because they got some big things right now. This is a common reason people give for being sceptical about the most important century hypothesis, and often for scepticism about pretty much any attempt at futurism, trying to predict key event in the world a long time from now, or what i call steering, trying to help the world navigate key future events. The idea of the scepticism is something like, even if we can't identify a particular weakness in arguments about key future events, perhaps we should be sceptical of our own ability to say anything meaningful at all the long run future. Hence, perhaps we should forget about theories of the future and focus on reducing suffering to day. ([Time 0:00:00](https://share.snipd.com/snip/c2865b22-b2e6-405e-b8a1-b37ee941f967))
- The Most Important Century Hypothesis
  Summary:
  The development of advanced dei could make this the most important century for humanity. A common reaction to this idea is one laid out by tyler cowan in a piece that i link to, where he says, how good we're, past thinkers, at predicting the future. Don't just select on those who are famous because they got some big things right now. The track record of futurists seems fine. This is holden karnowski doing an amateur read through of my blog post.
  Transcript:
  Speaker 1
  This is holden karnowski doing an amateur read through of my blog post. The track record of futurists seems fine. I've argued that the development of advanced dei could make this the most important century for humanity. A common reaction to this idea is one laid out by tyler cowan in a piece that i link to, where he says, how good we're, past thinkers, at predicting the future. Don't just select on those who are famous because they got some big things right now. This is a common reason people give for being sceptical about the most important century hypothesis, and often for scepticism about pretty much any attempt at futurism, trying to predict key event in the world a long time from now, or what i call steering, trying to help the world navigate key future events. ([Time 0:00:00](https://share.snipd.com/snip/68409618-054b-4c59-b90e-758161cd7891))
