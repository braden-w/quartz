---
tags:
 - On/Artificial_Intelligence/Safety
 - Type/Discussion
title: '2022-08-15 [[ML Safety Scholars Program]] Week 8 Discussion'
date: "2022-08-15"
date modified: "2022-08-16"
---

# 2022-08-15 [[ML Safety Scholars Program]] Week 8 Discussion
[[Cooperation is Not an Evolutionarily Stable Approach]]
[[Collusion (Game Theory)]]
[[Applying AI Collusion To Business Coll]]

## How AI Improving Epistemics and Improving Decision May Backfire
- Overconfidence, and being too eager to follow suggestions that are not correct
- Might not be [[Robustness|Robust]] and [[Adversarial Examples]] can cause a huge sway in recommendation
- Might recommend based off a single linear metric, even though there are multiple linear metric
	- See [[Why Charities Usually Don't Differ Astronomically in Expected Cost-Effectiveness]]
- Acting off the recommendation could actually lead to the market reacting in such a way that it becomes untrue
	- See [[Level 2 Chaos]] from [[The Black Swan|Black Swan]]
