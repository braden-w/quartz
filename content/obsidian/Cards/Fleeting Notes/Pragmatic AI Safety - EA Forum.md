---
tags:
 - On/Artificial_Intelligence/Safety
 - On/Effective_Altruim
 - On/Careers
 - Type/Source/Article
title: Pragmatic AI Safety - EA Forum
date: "2022-07-03"
date modified: "2022-07-16"
---

# Pragmatic AI Safety - EA Forum
Three Pillars
1. _ML research precedents_. Safety involves technical AI problems, and the ML community’s precedents enable it to be unusually effective at solving technical AI problems.
	> In general, ML researchers are skilled at adding arbitrary features to systems to improve capabilities, and many aspects of safety could be operationalized so as to be similarly improved. This property makes ML research precedents promising for solving technical ML problems, including many safety problems.
2. _Minimal capabilities externalities. Safety research at scale needs to be precautious and avoid advancing capabilities in the name of safety._

3. _Sociotechnical systems view. Preventing catastrophes requires more than technical work, such as improving incentives, safety culture, protocols, and so on._

## The Importance of Defining the Problem
[["A Problem Well-defined is a Problem Half Solved."]]

[[The Mere Formulation of a Problem is Often More Essential Than Its Solution, Which … Requires Creative Imagination and Marks Real Advances in science.]]

[[I Have Been Struck by How Important Measurement is… This May Seem Basic, but it is Amazing How Often it is Not Done and How Hard it is to Get Right.]]

[[If You Cannot Measure It, You Cannot Improve it.]]

[[For Better or Worse, Benchmarks Shape a Field.]]

> The [[The Bitter Lesson]] argues that there will be more creative destruction and that human ingenuity will matter less and less. Although we do not believe the following scenario is likely, in the long run, AI risk reduction may even be a matter of banal factors: compute, data, and engineering resources allocated towards safety goals, in comparison with other capabilities goals. The amount allocated towards these goals would depend on how important safety is to the system designers, which means safety buy-in among researchers and tech leaders would be a high priority.

## Overview of the AI Subfield
Image [[Classification]] like [[ImageNet]] and [[Computer Vision]]
> The [[ImageNet]] dataset, an old compilation of images and associated labels for those images, continues to drive the field. Why? It is a good microcosm. Researchers have found that performance on ImageNet is highly predictive of downstream performance in numerous applications like segmentation, clustering, object detection, and downstream image recognition. Many researchers also view image understanding as a problem that is upstream of video understanding, which is important for a whole range of additional applications.
Second Largest is [[Natural Language Processing]]

# References
- (References:: [Pragmatic AI Safety - EA Forum](https://forum.effectivealtruism.org/s/8EqNwueP6iw2BQpNo))
- (References:: [A Bird's Eye View of the ML Field [Pragmatic AI Safety #2] - EA Forum](https://forum.effectivealtruism.org/s/8EqNwueP6iw2BQpNo/p/PFxmd5bf7nqGNLYCg#Microcosms))
