---
tags:
 - On/Artificial_Intelligence/Neural_Network 
 - Type/Concept
title: Batch Normalization
date: "2022-07-31"
date modified: "2022-07-31"
---

# Batch Normalization
Normalizing activation vectors from hidden layers**Â using the first and the second statistical moments (mean and variance) of the current batch. This normalization step is applied right before (or right after) the nonlinear function

Computed differently during the training and the testing phase, in contrast to [[Layer Normalization]].

![300](https://miro.medium.com/max/1400/1*tcvRJN-OadhUyps6HSO0og.jpeg) ![300](https://miro.medium.com/max/1400/1*QcSkw489NgtpaMuwDhehaQ.jpeg)
[Group Normalization (Paper Explained) - YouTube](https://www.youtube.com/watch?v=l_3zj6HeWUE)
[Batch normalization in 3 levels of understanding | by Johann Huber | Towards Data Science](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338)
