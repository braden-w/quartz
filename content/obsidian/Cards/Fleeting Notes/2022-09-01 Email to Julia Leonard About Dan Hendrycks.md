---
tags:
 - On/Artificial_Intelligence/Safety
 - On/Writeup_Snippet/Email
title: '[[2022-09-01]] Email to Julia Leonard About Dan Hendrycks'
date: "2022-09-01"
date modified: "2022-09-01"
---

# [[2022-09-01]] Email to Julia Leonard About Dan Hendrycks
Dear Professor Leonard,

Thank you so much for graciously dealing with my very rude interruption in class today! I just got excited when you mentioned Hendrick's paper on the image classification section, as I coincidentally took a Machine Learning program taught by him this summer and we read papers with the exact same images. I'm a total novice on this stuff and could be wrong, but should this material be helpful for course materials in future years:

Neural Networks have surpassed “Top-5” Error rate of humans in many cases, and state of the art Neural Networks have done better than humans on the ImageNet dataset since 2015:

https://arxiv.org/pdf/1705.02498.pdf#:~:text=The%20performance%20of%20these%20deep,5%20error%20rate%20of%203.57%25

However, while models have surpassed humans in the “average” [[ImageNet]] classification exercise, the paper also talks about how these models are more susceptible to blur and noise

Hendryck’s paper talks about [[Robustness]], which is a machine learning model’s ability to be resilient to adversaries, unusual situations, and Black Swan events

It should just be noted that the examples you used were some handpicked examples of where examples obvious to humans can be misclassified by models 

The real beauty (applicable to this class) is that babies can see just a handful of examples and much more resilient, whereas Machine Learning models are trained on millions of images and need “adversarial training”. Machines are still behind humans in this regard

Also, just a point of clarification—ImageNet is a dataset of images, not a model itself. Machine Learning models are trained on ImageNet and benchmarked on it

Thank you so much! I really enjoyed today’s class—it was extremely engaging, and I especially enjoyed how you had us challenge our assumptions right off the bat. It was so good!

Best,

Braden Wong
