---
aliases: The Case for Systems Thinking
tags:
 - On/Artificial_Intelligence/Safety
 - Type/Source/Lecture
title: Introduction to STAMP
date: "2022-07-31"
date modified: "2022-08-03"
---

# Introduction to STAMP
Embrace the circular structure of safety. Safety is from a system as a whole.

## [[Safety]]
- The absense of loss
- Accident = Mishap = Loss
	- Avoid undesired outcomes that result in loss

## Causality Model
Explain how things work and help predict how they will behave in the future
No right or wrong model, only comparative effectiveness and usefulness

## [[Chain of Events (COE) Model]]
Assumes linear causality is enough to understand the world
![](https://i.imgur.com/JoCF8Xl.png)

## Selection of Root Cause is Arbitrary (It's Hard to Identify the Root Cause)
The events don't tell us enough. We need more information beyond the [[Chain of Events (COE) Model]]

### We Like the Concept of a "root cause"
- Usually focus on the operator or on physical failures
- Ignore system-related, management factors (not in the events)
- What "event" is involved in design of aircraft, design of pilot
- vehicle interface, competitive or productivity pressures?

### [[Root Cause Seduction]]
- We want a root cause so we make up a convenient one. Why?
- Provides an illusion of control
- So fix symptoms but not process that led to those symptoms

See [[Don't Focus on Pilot Failures]]

![300](https://i.imgur.com/qvXYg27.png)

## The Problem is Usually the Specification Requirements, Not the Pilot or Software
Navy fighter launching live instead of dummy missile (both pilot and software performed exactly as expected)

## How Software Has Revolutionized Engineering

### Software Does Not "Fail"
![](https://i.imgur.com/4PKA5gO.png)

Software is simply the design of a machine abstracted from its physical realization

### Software Allows Almost Unlimited System Complexity
- Can no longer
	- Plan, understand, anticipate, and guard against all undesired system behavior
	- Exhaustively test to get out all design errors
- Context determines whether software is safe

## Ways to Cope with Complexity
- [[Analytic Decomposition|Divide and Conquer]]
- Statistics
- [[Systems Theory]]

## [[Safety]] And Security Are [[Emergent Properties]]

## STAMP
- A new, more powerful accident/loss causality model that capures nonlinear causality
- Based on [[Systems Theory]], not [[reliability theory]]
- Defines accidents/losses as a dynamic control problem (vs. a
- failure problem)
- Applies to VERY complex systems
- Includes
	- Scenarios from traditional hazard analysis methods (failure events)
	- Component interaction accidents
	- Software and system design errors
	- Human errors
	- Entire socio-technical system (not just technical part) 139

### Model
![300](https://i.imgur.com/up3XDq6.png)

### Capturing More Types of Causality Than Linear
![300](https://i.imgur.com/szYOJv3.png)

### Example - Columbia Shuttle Loss
![](https://i.imgur.com/3p4olxE.png)
[[Reality is Made up of Circles, but We See Straight Lines]]
- Embrace the circular nature of safety

In [[Chain of Events (COE) Model|event oriented]] thinking everything can be explained by causal chains of events. From this perspective the root causes are the events starting the chains of cause and effect, such as A and B.

In [[Systems Theory|systems thinking ]]a system's behavior emerges from the structure of its feedback loops. Root causes are not individual nodes. They are the forces emerging from particular feedback loops.

# References
- (References:: [Introduction to STAMP (Part 1 and 2) - YouTube](https://www.youtube.com/watch?v=_ptmjAbacMk))
