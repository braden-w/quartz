---
tags:
 - On/Artificial_Intelligence/Safety
 - Type/Concept
title: Robustness
date: "2022-07-28"
date modified: "2022-08-12"
---

# Robustness
Create models that are resilient to adversaries, unusual situations, and Black Swan events.

## Adversarial Robustness
Handle unforseen attacks.

One way to think about it is in terms of the ability of a model to resist being fooled by adversarial examples. That is, robustness against adversarial examples is the ability of a model to maintain its accuracy when presented with inputs that have been deliberately designed to fool it.

Another way to think about adversarial robustness is in terms of the ability of a model to learn from data that is "adversarially corrupted" in some way. That is, the model is able to learn from data that has been deliberately modified in a way that is intended to make it inaccurate.

Finally, adversarial robustness can also be thought of as the ability of a model to make accurate predictions despite the presence of noise in the input data. That is, the model is able to filter out the noise and still make accurate predictions.

## Black Swan Robustness
Endure once-in-a-century events.

# References
- (References:: [EA Forum: Robustness](https://forum.effectivealtruism.org/posts/hNPCo4kScxccK9Ham/open-problems-in-ai-x-risk-pais-5#Robustness))
