---
tags:
#On/Effective_Altruim 
#Type/Content/Texts 
date: "2022-06-16"
date modified: "2022-06-16"
title: 2022-06-07 Slack Messages to YEA About
---

# 2022-06-07 Slack Messages to YEA About
We have just started and I haven’t been able to talk to Koray 1-1 yet about his intentions of a Biorisk reading group/fellowship (but intend to). Note that this is a program and not an org/clubGiven that Koray’s biorisk work would be relatively longtermist-aligned, it seemed less of a leap to also have him work on the creation of a longtermist group, under which the Biorisk program could be under.Simon created an [application](https://docs.google.com/document/d/108cZWbeHaSaFANzS0ceuFfANA7GW_NjWKbGSYDeiAUI/edit?usp=sharing) that Koray and possibly Will will be assisting. To address a potential conflict of interest, I didn’t know that this was being created or that I was listed as president until recently (and am open to finding other people to run the club). Another task of this group is finding additional people who can fill and or replace the leadership structure (edited)

Talked a bit about this with Simon, then Koray. With Simon, we shared a vision to make YERI and YEA form a “balanced venn diagram”, where both attract different audience with overlap in the middle (not one taking all the members of the other). With Koray, we were thinking of having YERI start out with Existential-Risk-Aligned curriculum—so fellowships in AI, Biorisk, and maybe Nuclear or other areas. This feels intuitive to me because I felt like YEA focuses a lot on intro and indepth, but AI /existential fellowships are not particularly our focus  (for example, last semester we had both the EA Cambridge and internal AI Governance fellowship, attendance for the latter was not very high) and it might not be a bad idea to have these fellowships enjoy the resources of a dedicated team in an adjacent organization
