---
tags:
 - On/Artificial_Intelligence/Safety
 - Type/Source/Video
title: '[[LaMDA]] is Not Sentient'
date: "2022-08-08"
date modified: "2022-08-08"
---

# [[LaMDA]] Is Not Sentient
- [[Calling AI Sentient is Like Saying a Submarine Can Swim. We May Need To Change Our State of ]]
- [[Prompt Engineering]]
- Knowledgeable, Friendly, Always Helpful Robot
	- [[Leading Question]]
	- It's not [[LaMDA]] that brings up the topic of [[Sentience]], but the Google Engineer
		- If you ask it "Is It True that You're Sentient", then it will go along
		- If you ask it "Is It False that You're Sentient", then it will go along and say it's just a ML model
- The Progressive Increase
	- Models used to be [[Supervised Learning]] and so they were narrowly trained to do sentiment analysis, etc.
	- Then fed massive troves of unlabeled data, [[Unsupervised Learning]]
	- GPT-3 was trained on massive amounts of data, used a relatively outdated model, and still had crazy results
- [[Scaling Hypothesis]]
	- Deep Learning Models are currently doubling in size every 3 months

# References
- (References:: [Not So Sentient After All - YouTube](https://www.youtube.com/watch?v=lRp9y_VRb3g))
