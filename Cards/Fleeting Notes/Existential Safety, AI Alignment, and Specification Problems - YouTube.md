---
tags:
 - On/Artificial_Intelligence/Safety
 - Type/Source/Lecture
title: 'Existential Safety, AI Alignment, and Specification Problems - YouTube'
date: "2022-08-17"
date modified: "2022-08-18"
---

# Existential Safety, AI Alignment, and Specification Problems - YouTube
- [[Reward Gaming]]
- [[Goal Misgeneralization]]
- [[Capability Failure]]
	- The agent's observations are corrupted by changing contrast.

# References
- (References:: [Existential Safety, AI Alignment, and Specification Problems - YouTube](https://www.youtube.com/watch?v=vZybJ_bEZ7E))
