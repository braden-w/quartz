---
tags:
 - On/Artificial_Intelligence
 - Type/Source/Article
title: Blake Richards on Why He is Skeptical of Existential Risk From AI - EA Forum
date: "2022-07-19"
date modified: "2022-07-19"
---

# Blake Richards on Why He is Skeptical of Existential Risk From AI - EA Forum

## Training in a Domain is Better for [[Transfer Effects]] Than Training Across All Tasks
> The Gato paper from DeepMind actually shows, if you look at their data, that they’re still getting better transfer effects if you train in domain than if you train across all possible tasks.

## Scale is Not All You Need
> "Will scale be literally all you need? No, I don’t think so. In so far as… I think that right off the bat, in addition to scale, you’re going to need careful consideration of the data that you train it on. And you’re never going to be able to escape that. So human-like decisions on the data you need is something you cannot put aside totally. But the other thing is, I suspect that architecture is going to matter in the long run.
>
> I think we’re going to find that systems that have appropriate architectures for solving particular types of problems will again outperform those that don’t have the appropriate architectures for those problems. […] my personal bet is that we will find new ways of doing transformers or self-attention plus other stuff that again makes a big step change in our capabilities."

# References
- (References:: [Blake Richards on Why he is Skeptical of Existential Risk from AI - EA Forum](https://forum.effectivealtruism.org/posts/BqokXcCQrvkk2BktH/blake-richards-on-why-he-is-skeptical-of-existential-risk#On_Recursive_Self_Improvement))
