---
title: ReLU (Rectified Linear Unit)
date: "2022-07-26"
date modified: "2022-07-26"
---

# ReLU (Rectified Linear Unit)
A type of [[Activation Function]], and the most common one.
![](https://i.imgur.com/QjA0TvF.png)

# References
- (References:: [Lecture 5: Neural Networks - YouTube](https://www.youtube.com/watch?v=g6InpdhUblE&list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r))
