<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Type/Source/Paper on</title><link>https://braden-w.github.io/quartz/tags/Type/Source/Paper/</link><description>Recent content in Type/Source/Paper on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://braden-w.github.io/quartz/tags/Type/Source/Paper/index.xml" rel="self" type="application/rss+xml"/><item><title>Utilitarians Should Be Virtue Theorists</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Utilitarians-Should-Be-Virtue-Theorists/</link><pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Utilitarians-Should-Be-Virtue-Theorists/</guid><description>Utilitarians Should Be Virtue Theorists References (References:: When Utilitarians Should Be Virtue Theorists | Utilitas | Cambridge Core) (References:: Virtues for Real-World Utilitarians - EA Forum)</description></item><item><title>Kai's Mountain Paper</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Kais-Mountain-Paper/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Kais-Mountain-Paper/</guid><description>Kai&amp;rsquo;s Mountain Paper References (References:: Datumless Topography: A Universally Consistent Way to Quantify Relief | Abstract)</description></item><item><title>Adam - A Method for Stochastic Optimization | Abstract</title><link>https://braden-w.github.io/quartz/obsidian/Adam-A-Method-for-Stochastic-Optimization-Abstract/</link><pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Adam-A-Method-for-Stochastic-Optimization-Abstract/</guid><description>Adam - A Method for Stochastic Optimization | Abstract Adam is an efficient, moment-based algorithm for stochastic optimization that is well-suited for large-scale problems with noisy or sparse gradients.</description></item><item><title>Attention Is All You Need</title><link>https://braden-w.github.io/quartz/obsidian/Attention-Is-All-You-Need/</link><pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Attention-Is-All-You-Need/</guid><description>Attention Is All You Need The paper, &amp;ldquo;Attention is All You Need&amp;rdquo; explores the role of attention in neural networks. It argues that attention is the key to understanding how neural networks function.</description></item><item><title>BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding - Abstract</title><link>https://braden-w.github.io/quartz/obsidian/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding-Abstract/</link><pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding-Abstract/</guid><description>BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding - Abstract This research paper discusses the pre-training of deep bidirectional transformers for language understanding using the BERT model.</description></item><item><title>Deep Residual Learning for Image Recognition</title><link>https://braden-w.github.io/quartz/obsidian/Deep-Residual-Learning-for-Image-Recognition/</link><pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Deep-Residual-Learning-for-Image-Recognition/</guid><description>Deep Residual Learning for Image Recognition This paper presents a residual learning framework to ease the training of deep neural networks.</description></item><item><title>Layer Normalization</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Layer-Normalization/</link><pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Layer-Normalization/</guid><description>Layer Normalization Improvements over [[Batch Normalization]]
Can deal with sequences Any batch number sworks Can paralllize Better for RNNs Paper Summary This research paper explores the new technique of layer normalization.</description></item><item><title>Unsolved Problems in ML Safety</title><link>https://braden-w.github.io/quartz/obsidian/Unsolved-Problems-in-ML-Safety/</link><pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Unsolved-Problems-in-ML-Safety/</guid><description>Unsolved Problems in ML Safety Unsolved Problems in ML Safety is a research paper by Dan Hendrycks et. al that discusses some of the challenges associated with ensuring the safety of machine learning systems.</description></item><item><title>Dropout - A Simple Way to Prevent Neural Networks From Overfitting</title><link>https://braden-w.github.io/quartz/obsidian/Dropout-A-Simple-Way-to-Prevent-Neural-Networks-From-Overfitting/</link><pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Dropout-A-Simple-Way-to-Prevent-Neural-Networks-From-Overfitting/</guid><description>Dropout - A Simple Way to Prevent Neural Networks From Overfitting This research paper explores the idea of using dropout to prevent overfitting in deep neural networks.</description></item><item><title>Google AI BlogMinervaSolving Quantitative Reasoning Problems with Language Models</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Google-AI-BlogMinervaSolving-Quantitative-Reasoning-Problems-with-Language-Models/</link><pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Google-AI-BlogMinervaSolving-Quantitative-Reasoning-Problems-with-Language-Models/</guid><description>Google AI BlogMinervaSolving Quantitative Reasoning Problems with Language Models References (References:: Google AI Blog: Minerva: Solving Quantitative Reasoning Problems with Language Models)</description></item><item><title>Scaling Laws for Neural Language Models</title><link>https://braden-w.github.io/quartz/obsidian/Sources/Articles/Scaling-Laws-for-Neural-Language-Models/</link><pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Sources/Articles/Scaling-Laws-for-Neural-Language-Models/</guid><description>Scaling Laws for Neural Language Models Larger models are significantly more sample-efficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.</description></item></channel></rss>