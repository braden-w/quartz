<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>On/Existential_Risk on</title><link>https://braden-w.github.io/quartz/tags/On/Existential_Risk/</link><description>Recent content in On/Existential_Risk on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://braden-w.github.io/quartz/tags/On/Existential_Risk/index.xml" rel="self" type="application/rss+xml"/><item><title>How to Convince Someone of AI Risk</title><link>https://braden-w.github.io/quartz/obsidian/Content/Blog/How-to-Convince-Someone-of-AI-Risk/</link><pubDate>Wed, 22 Jun 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Content/Blog/How-to-Convince-Someone-of-AI-Risk/</guid><description>How to Convince Someone of AI Risk The most effective way to change someone&amp;rsquo;s mind about this is to frame it .</description></item><item><title>Artificial Intelligence</title><link>https://braden-w.github.io/quartz/obsidian/Sources/Books/Artificial-Intelligence/</link><pubDate>Thu, 16 Jun 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Sources/Books/Artificial-Intelligence/</guid><description>Artificial Intelligence [[Artificial General Intelligence (AGI)]]
[[Machine Learning]]
[[Deep Learning]]</description></item><item><title>Biorisk</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Permanent-Notes/Biorisk/</link><pubDate>Thu, 16 Jun 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Permanent-Notes/Biorisk/</guid><description>Biorisk</description></item><item><title>Nuclear Risk</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Nuclear-Risk/</link><pubDate>Thu, 16 Jun 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Nuclear-Risk/</guid><description>Nuclear Risk</description></item></channel></rss>