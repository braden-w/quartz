<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>On/Machine_Learning/Deep_Learning on</title><link>https://braden-w.github.io/quartz/tags/On/Machine_Learning/Deep_Learning/</link><description>Recent content in On/Machine_Learning/Deep_Learning on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://braden-w.github.io/quartz/tags/On/Machine_Learning/Deep_Learning/index.xml" rel="self" type="application/rss+xml"/><item><title>[[Deep Learning]] For NLP</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Deep-Learning-For-NLP/</link><pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Deep-Learning-For-NLP/</guid><description>[[Deep Learning]] For NLP Lots of progress recently People trust [[Wikipedia]], [[Google Translate]], etc. more than other people, in some cases Language models assign probability to text $p(x_0, …, x_n)$ Most popular method is to factorize distribution using chain rule: $$p(x_0,…x_n) = p(x_0)p(x_1 \mid x_0) \cdots p(x_n \mid x_{n-1})$$ Neural Language Models [[Convolutional Language Models]] (CLMs) Earliest</description></item><item><title>Deep Residual Learning for Image Recognition</title><link>https://braden-w.github.io/quartz/obsidian/Deep-Residual-Learning-for-Image-Recognition/</link><pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Deep-Residual-Learning-for-Image-Recognition/</guid><description>Deep Residual Learning for Image Recognition This paper presents a residual learning framework to ease the training of deep neural networks.</description></item><item><title>Deep Learning</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Deep-Learning/</link><pubDate>Sat, 16 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Deep-Learning/</guid><description>Deep Learning [[Symbolic Learning Vs. Deep Learning]]
How Deep Learning Got Popular Data Size Increase in Compute Deep Learning entered Imagenet in 2012, and the competition hasn&amp;rsquo;t been the same ever since, quickly surpassing human level image recognition</description></item><item><title>Natural Language Processing</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Natural-Language-Processing/</link><pubDate>Sat, 16 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Natural-Language-Processing/</guid><description>Natural Language Processing</description></item></channel></rss>