<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>On/Artificial_Intelligence/Safety on</title><link>https://braden-w.github.io/quartz/tags/On/Artificial_Intelligence/Safety/</link><description>Recent content in On/Artificial_Intelligence/Safety on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://braden-w.github.io/quartz/tags/On/Artificial_Intelligence/Safety/index.xml" rel="self" type="application/rss+xml"/><item><title>EA might not be the best platform for AI safety research</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/EA-might-not-be-the-best-platform-for-AI-safety-research/</link><pubDate>Thu, 18 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/EA-might-not-be-the-best-platform-for-AI-safety-research/</guid><description>EA Might Not Be the Best Platform for AI Safety Research References (References:: undefined)</description></item><item><title>Why EAs Are Skeptical About AI Safety - EA Forum</title><link>https://braden-w.github.io/quartz/obsidian/Sources/Clippings/Why-EAs-Are-Skeptical-About-AI-Safety-EA-Forum/</link><pubDate>Thu, 18 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Sources/Clippings/Why-EAs-Are-Skeptical-About-AI-Safety-EA-Forum/</guid><description>Why EAs Are Skeptical About AI Safety - EA Forum I found this section on why [[EA might not be the best platform for AI safety research]] particularly salient:</description></item><item><title>Existential Safety, AI Alignment, and Specification Problems - YouTube</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Existential-Safety-AI-Alignment-and-Specification-Problems-YouTube/</link><pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Existential-Safety-AI-Alignment-and-Specification-Problems-YouTube/</guid><description>Existential Safety, AI Alignment, and Specification Problems - YouTube [[Reward Gaming]] [[Goal Misgeneralization]] [[Capability Failure]] The agent&amp;rsquo;s observations are corrupted by changing contrast.</description></item><item><title>Goal Misgeneralization</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Goal-Misgeneralization/</link><pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Goal-Misgeneralization/</guid><description>Goal Misgeneralization Even with The policy is capable The policy is goal-directed Yet it still fails! References (References:: undefined)</description></item><item><title>Normative Factors</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Normative-Factors/</link><pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Normative-Factors/</guid><description>Normative Factors References (References:: machine_ethics - Google Slides)</description></item><item><title>Reward Gaming</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Reward-Gaming/</link><pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Reward-Gaming/</guid><description>Reward Gaming References (References:: undefined)</description></item><item><title>2022-08-16 HOlden Karnofski Talk</title><link>https://braden-w.github.io/quartz/obsidian/Sources/Daily-Note/2022-08-16-HOlden-Karnofski-Talk/</link><pubDate>Tue, 16 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Sources/Daily-Note/2022-08-16-HOlden-Karnofski-Talk/</guid><description>2022-08-16 HOlden Karnofski Talk The odds of AI Destroying Humanitiy is between 10 and 90% Not the same 98% of Yulkowsky This is a wide range, still disproves range that we&amp;rsquo;re too doomed or too okay</description></item><item><title>2022-08-15 [[ML Safety Scholars Program]] Week 8 Discussion</title><link>https://braden-w.github.io/quartz/obsidian/Sources/Daily-Note/2022-08-15-ML-Safety-Scholars-Program-Week-8-Discussion/</link><pubDate>Mon, 15 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Sources/Daily-Note/2022-08-15-ML-Safety-Scholars-Program-Week-8-Discussion/</guid><description>2022-08-15 [[ML Safety Scholars Program]] Week 8 Discussion [[Cooperation is Not an Evolutionarily Stable Approach]] [[Collusion (Game Theory)]] [[Applying AI Collusion To Business Coll]]</description></item><item><title>Applying AI Collusion To Business Coll</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Applying-AI-Collusion-To-Business-Coll/</link><pubDate>Mon, 15 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Applying-AI-Collusion-To-Business-Coll/</guid><description>Applying AI Collusion To Business Coll Businesses are not always cooperaterative, as they have the option to cooperate and fix prices, in what is called [[Collusion (Game Theory)|Collusion]].</description></item><item><title>Power Seeking AI</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Power-Seeking-AI/</link><pubDate>Mon, 15 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Power-Seeking-AI/</guid><description>Power Seeking AI Consider Cooperative AI that [[Collusion (Game Theory)|Colludes]] against humans to seek power.</description></item><item><title>[[LaMDA]] is Not Sentient</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/LaMDA-Is-Not-Sentient/</link><pubDate>Mon, 08 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/LaMDA-Is-Not-Sentient/</guid><description>[[LaMDA]] Is Not Sentient [[Calling AI Sentient is Like Saying a Submarine Can Swim. We May Need To Change Our State of ]] [[Prompt Engineering]] Knowledgeable, Friendly, Always Helpful Robot [[Leading Question]] It&amp;rsquo;s not [[LaMDA]] that brings up the topic of [[Sentience]], but the Google Engineer If you ask it &amp;ldquo;Is It True that You&amp;rsquo;re Sentient&amp;rdquo;, then it will go along If you ask it &amp;ldquo;Is It False that You&amp;rsquo;re Sentient&amp;rdquo;, then it will go along and say it&amp;rsquo;s just a ML model The Progressive Increase Models used to be [[Supervised Learning]] and so they were narrowly trained to do sentiment analysis, etc.</description></item><item><title>Model (AI)</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Model-AI/</link><pubDate>Mon, 08 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Model-AI/</guid><description>Model (AI) References (References:: undefined)</description></item><item><title>Emergent Behaviors</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Emergent-Behaviors/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Emergent-Behaviors/</guid><description>Emergent Behaviors References (References:: undefined)</description></item><item><title>False Positive Rate (FPR))</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/False-Positive-Rate-FPR/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/False-Positive-Rate-FPR/</guid><description>False Positive Rate (FPR)) True Negatives / All Negatives
References (References:: undefined)</description></item><item><title>Goodhart's Law</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Goodharts-Law/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Goodharts-Law/</guid><description>Goodhart&amp;rsquo;s Law &amp;ldquo;Any observed [[Statistical Regularity]] will tend to collapse once pressure is placed upon it&amp;rdquo; References (References:: undefined)</description></item><item><title>GPT-3 Learned to do 3-Digit Addition, Even Though</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/GPT-3-Learned-to-do-3-Digit-Addition-Even-Though/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/GPT-3-Learned-to-do-3-Digit-Addition-Even-Though/</guid><description>GPT-3 Learned to do 3-Digit Addition, Even Though An example of unexpected behavior emerging.
References (References:: undefined)</description></item><item><title>Grokking</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Grokking/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Grokking/</guid><description>Grokking Capabilities emerge not with scale, but by training for a long time.</description></item><item><title>Proxy Gaming</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Proxy-Gaming/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Proxy-Gaming/</guid><description>Proxy Gaming When the misspecified proxy function is over-optimized.
References (References:: undefined)</description></item><item><title>Rotation Prediction</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Rotation-Prediction/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Rotation-Prediction/</guid><description>Rotation Prediction References (References:: undefined)</description></item><item><title>True Positive Rate (TPR)</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/True-Positive-Rate-TPR/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/True-Positive-Rate-TPR/</guid><description>True Positive Rate (TPR) True Positives / All Positives
References (References:: undefined)</description></item><item><title>Reliability</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Reliability/</link><pubDate>Thu, 04 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Reliability/</guid><description>Reliability References (References:: undefined)</description></item><item><title>Ability to Cope</title><link>https://braden-w.github.io/quartz/obsidian/Ability-to-Cope/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Ability-to-Cope/</guid><description>Ability to Cope Ability to efficiently recover from the effects of hazards</description></item><item><title>Black Balls</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Black-Balls/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Black-Balls/</guid><description>Black Balls A technology that invariably or by default destroys the civilization that invents it
References (References:: The Vulnerable World Hypothesis - Bostrom - 2019 - Global Policy - Wiley Online Library)</description></item><item><title>Boe Tie Model</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Boe-Tie-Model/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Boe-Tie-Model/</guid><description>Boe Tie Model Preventative Barrier Prevent initiating hazardous event (decrease probability (event))
Protective Barrier Minimize hazardous event consequences (decrease impact(event)) References (References:: undefined)</description></item><item><title>Disaster Risk Equation</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Disaster-Risk-Equation/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Disaster-Risk-Equation/</guid><description>Disaster Risk Equation [[Vulnerability (AI Safety)]] $\times$ [[Hazard (AI Safety)|Hazard]] Exposure $\times$ [[Hazard (AI Safety)]] [[How the Four Unsolved Problems in ML Safety Relate to Disaster Risk Equation]] See [[Extended Disaster Risk Equation]].</description></item><item><title>Exposure</title><link>https://braden-w.github.io/quartz/obsidian/Exposure/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Exposure/</guid><description>Exposure Extent to which elements (e.g., people, property, systems) are subjected or exposed to [[Hazard (AI Safety)|Hazards]]</description></item><item><title>Extended Disaster Risk Equation</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Extended-Disaster-Risk-Equation/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Extended-Disaster-Risk-Equation/</guid><description>Extended Disaster Risk Equation [[Disaster Risk Equation]] divided by [[Ability to Cope]]
References (References:: undefined)</description></item><item><title>Failure Mode</title><link>https://braden-w.github.io/quartz/obsidian/Failure-Mode/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Failure-Mode/</guid><description>Failure Mode A possible way a system might fail</description></item><item><title>Hazard (AI Safety)</title><link>https://braden-w.github.io/quartz/obsidian/Hazard-AI-Safety/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Hazard-AI-Safety/</guid><description>Hazard (AI Safety) A source of danger with the potential to harm</description></item><item><title>Honest AI</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Honest-AI/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Honest-AI/</guid><description>Honest AI Make the AI feed us accurate information.
Interesting Criticism Honesty could make an AI critical and sad.
References (References:: Open Problems in AI X-Risk [PAIS #5] - EA Forum)</description></item><item><title>Intro to ML Safety</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Intro-to-ML-Safety/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Intro-to-ML-Safety/</guid><description>Intro to ML Safety [[Four Unsolved Problems in ML Safety]]
[[Risk Decomposition]]
Risk Decomposition Risk Analysis Definitions [[Failure Mode]] [[Hazard (AI Safety)]] [[Vulnerability (AI Safety)]] [[Threat]] [[Exposure]] [[Ability to Cope]]</description></item><item><title>Long Tailed Distributions</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Long-Tailed-Distributions/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Long-Tailed-Distributions/</guid><description>Long Tailed Distributions A long tail distribution has tails that taper off gradually rather than drop off sharply. The head often accounts for way more than the sum of everything else combined.</description></item><item><title>Monitoring</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Monitoring/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Monitoring/</guid><description>Monitoring References (References:: Open Problems in AI X-Risk [PAIS #5] - EA Forum)</description></item><item><title>Swiss Cheese Model</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Swiss-Cheese-Model/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Swiss-Cheese-Model/</guid><description>Swiss Cheese Model No system is completely safe, but that multiple layers of safety can help to mitigate risks.</description></item><item><title>Threat</title><link>https://braden-w.github.io/quartz/obsidian/Threat/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Threat/</guid><description>Threat A [[Hazard (AI Safety)]] with intent to exploit a [[Vulnerability (AI Safety)]]</description></item><item><title>Trojan Horse Models</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Trojan-Horse-Models/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Trojan-Horse-Models/</guid><description>Trojan Horse Models References (References:: Open Problems in AI X-Risk [PAIS #5] - EA Forum)</description></item><item><title>Vulnerability (AI Safety)</title><link>https://braden-w.github.io/quartz/obsidian/Vulnerability-AI-Safety/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Vulnerability-AI-Safety/</guid><description>Vulnerability (AI Safety) A factor or process that increases susceptibility to the damaging effects of [[Hazard (AI Safety)|Hazards]]</description></item><item><title>Emergent Properties</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Emergent-Properties/</link><pubDate>Sun, 31 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Emergent-Properties/</guid><description>Emergent Properties Some properties can only be treated adequately in their entirety, taking into account all social and technical aspects.</description></item><item><title>Introduction to STAMP</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Introduction-to-STAMP/</link><pubDate>Sun, 31 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Introduction-to-STAMP/</guid><description>Introduction to STAMP Embrace the circular structure of safety. Safety is from a system as a whole.
[[Safety]] The absense of loss Accident = Mishap = Loss Avoid undesired outcomes that result in loss Causality Model Explain how things work and help predict how they will behave in the future No right or wrong model, only comparative effectiveness and usefulness</description></item><item><title>Unsolved Problems in ML Safety</title><link>https://braden-w.github.io/quartz/obsidian/Unsolved-Problems-in-ML-Safety/</link><pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Unsolved-Problems-in-ML-Safety/</guid><description>Unsolved Problems in ML Safety Unsolved Problems in ML Safety is a research paper by Dan Hendrycks et. al that discusses some of the challenges associated with ensuring the safety of machine learning systems.</description></item><item><title>Robustness</title><link>https://braden-w.github.io/quartz/obsidian/Robustness/</link><pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Robustness/</guid><description>Robustness Create models that are resilient to adversaries, unusual situations, and Black Swan events.
Adversarial Robustness Handle unforseen attacks.
One way to think about it is in terms of the ability of a model to resist being fooled by adversarial examples.</description></item><item><title>Narrow AI</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Narrow-AI/</link><pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Narrow-AI/</guid><description>Narrow AI</description></item><item><title>Call to Vigilance</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Call-to-Vigilance/</link><pubDate>Tue, 19 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Call-to-Vigilance/</guid><description>Call to Vigilance [[PASTA]]
References (References:: Call to Vigilance)</description></item><item><title>Pragmatic AI Safety - EA Forum</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Pragmatic-AI-Safety-EA-Forum/</link><pubDate>Sun, 03 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Pragmatic-AI-Safety-EA-Forum/</guid><description>Pragmatic AI Safety - EA Forum Three Pillars
ML research precedents. Safety involves technical AI problems, and the ML communityâ€™s precedents enable it to be unusually effective at solving technical AI problems.</description></item></channel></rss>