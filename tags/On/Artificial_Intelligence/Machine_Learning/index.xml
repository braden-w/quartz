<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>On/Artificial_Intelligence/Machine_Learning on</title><link>https://braden-w.github.io/quartz/tags/On/Artificial_Intelligence/Machine_Learning/</link><description>Recent content in On/Artificial_Intelligence/Machine_Learning on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://braden-w.github.io/quartz/tags/On/Artificial_Intelligence/Machine_Learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Helpful Machine Learning Resources</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Helpful-Machine-Learning-Resources/</link><pubDate>Fri, 19 Aug 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Helpful-Machine-Learning-Resources/</guid><description>Helpful Machine Learning Resources https://cjquines.com/files/machinelearning.pdf</description></item><item><title>AlphaGo</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/AlphaGo/</link><pubDate>Sun, 31 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/AlphaGo/</guid><description>AlphaGo</description></item><item><title>Adam - A Method for Stochastic Optimization | Abstract</title><link>https://braden-w.github.io/quartz/obsidian/Adam-A-Method-for-Stochastic-Optimization-Abstract/</link><pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Adam-A-Method-for-Stochastic-Optimization-Abstract/</guid><description>Adam - A Method for Stochastic Optimization | Abstract Adam is an efficient, moment-based algorithm for stochastic optimization that is well-suited for large-scale problems with noisy or sparse gradients.</description></item><item><title>Attention Is All You Need</title><link>https://braden-w.github.io/quartz/obsidian/Attention-Is-All-You-Need/</link><pubDate>Sat, 30 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Attention-Is-All-You-Need/</guid><description>Attention Is All You Need The paper, &amp;ldquo;Attention is All You Need&amp;rdquo; explores the role of attention in neural networks. It argues that attention is the key to understanding how neural networks function.</description></item><item><title>Neural Network</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Neural-Network/</link><pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Neural-Network/</guid><description>Neural Network A deep single end-to-end pipeline that takes all the raw input on one side (pixels) and on the other side, spits out the output.</description></item><item><title>The Problem with [[Feature Representations]] and Feature Extraction</title><link>https://braden-w.github.io/quartz/obsidian/The-Problem-with-Feature-Representations-and-Feature-Extraction/</link><pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/The-Problem-with-Feature-Representations-and-Feature-Extraction/</guid><description>The Problem with [[Feature Representations]] and Feature Extraction We can use [[Feature Representations]], like [[Color Histogram]] or [[Bag of Words Approach]], and even use combinations of feature representations.</description></item><item><title>Recurrent Neural Network</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Recurrent-Neural-Network/</link><pubDate>Mon, 25 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Recurrent-Neural-Network/</guid><description>Recurrent Neural Network Inspiration One to many problems Labelling images Image -&amp;gt; Many labels Many to one Classifying videos Sequences of images -&amp;gt; Single classification Many to many Labelling videos Sequences of images -&amp;gt; Many labels But even good for non-sequential data How [[Recurrent Neural Network]]s Work RNNs have an &amp;ldquo;internal state&amp;rdquo; that is updated as a sequence is processed Sampling what the model thinks is the next character, then feeding that back into the model as next input Example: Language Modelling Note the use of [[One-Hot Encoding]] on the input.</description></item><item><title>Google AI BlogMinervaSolving Quantitative Reasoning Problems with Language Models</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Google-AI-BlogMinervaSolving-Quantitative-Reasoning-Problems-with-Language-Models/</link><pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Google-AI-BlogMinervaSolving-Quantitative-Reasoning-Problems-with-Language-Models/</guid><description>Google AI BlogMinervaSolving Quantitative Reasoning Problems with Language Models References (References:: Google AI Blog: Minerva: Solving Quantitative Reasoning Problems with Language Models)</description></item><item><title>Perceptron Algorithm</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Perceptron-Algorithm/</link><pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Perceptron-Algorithm/</guid><description>Perceptron Algorithm One of the earliest examples of [[Artificial Intelligence|Deep Learning]], used to discern difference between alphabet.
A model that updates on the basis of whether the dot product is positive or negative.</description></item><item><title>Entry Level Machine Learning is Actually Data Analyst. ML Engineer Requires 3-5 Years of Experience</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Entry-Level-Machine-Learning-is-Actually-Data-Analyst.-ML-Engineer-Requires-3-5-Years-of-Experience/</link><pubDate>Sat, 18 Jun 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Entry-Level-Machine-Learning-is-Actually-Data-Analyst.-ML-Engineer-Requires-3-5-Years-of-Experience/</guid><description>Entry Level Machine Learning is Actually Data Analyst. ML Engineer Requires 3-5 Years of Experience</description></item><item><title>Most Projects Are Not Deep Learning, but Classification Regression on Structured Data.</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Most-Projects-Are-Not-Deep-Learning-but-Classification-Regression-on-Structured-Data./</link><pubDate>Sat, 18 Jun 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/Most-Projects-Are-Not-Deep-Learning-but-Classification-Regression-on-Structured-Data./</guid><description>Most Projects Are Not Deep Learning, but Classification Regression on Structured Data. References (References:: https://youtube.com/clip/UgkxzlRfdG4cU13s9A1RmC1zh0L-yv5Ckz0O)</description></item><item><title>The top model for all classification regression problems is gradient boosters (and most likely what you'll be working with). (and most likely what you'll be working with).</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/-The-top-model-for-all-classification-regression-problems-is-gradient-boosters-and-most-likely-what-youll-be-working-with.-/</link><pubDate>Sat, 18 Jun 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Fleeting-Notes/-The-top-model-for-all-classification-regression-problems-is-gradient-boosters-and-most-likely-what-youll-be-working-with.-/</guid><description>The Top Model for All Classification Regression Problems is Gradient Boosters (and Most Likely What You&amp;rsquo;ll Be Working with).</description></item><item><title>GPT-3</title><link>https://braden-w.github.io/quartz/obsidian/Cards/Journal/Personal-Life/GPT-3/</link><pubDate>Thu, 09 Jun 2022 00:00:00 +0000</pubDate><guid>https://braden-w.github.io/quartz/obsidian/Cards/Journal/Personal-Life/GPT-3/</guid><description>GPT-3 [[Artificial Intelligence]]</description></item></channel></rss>